{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "AQkp9jw__r9j"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import random as rn\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import *\n",
        "import keras\n",
        "from keras.applications import mobilenet_v2\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import optimizers\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.applications.mobilenet_v2 import preprocess_input, decode_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "KquTwLiFOAai"
      },
      "outputs": [],
      "source": [
        "SEED = 12345\n",
        "os.environ['PYTHONHASHSEED']=str(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "rn.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "8DbFadz-XNj6"
      },
      "outputs": [],
      "source": [
        "COLOR_MODE = \"B\"\r\n",
        "\r\n",
        "EPOCHS = 50\r\n",
        "BATCH_SIZE = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "LITyfNXg1_Yk"
      },
      "outputs": [],
      "source": [
        "def LeNet_5():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32,(5,5),strides=(1,1),input_shape=(32,32,1),padding='same',activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(64,(5,5),strides=(1,1),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128,activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10,activation='softmax'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgbFXvsg_r9p",
        "outputId": "9717617b-f89f-4a7a-bdb9-141163962324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 32, 32, 32)        832       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               524416    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 577,930\n",
            "Trainable params: 577,866\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Load MobileNet model\n",
        "model = LeNet_5()\n",
        "model.summary()\n",
        "# opt = optimizers.SGD(lr=1e-2, momentum=0.9),\n",
        "opt = optimizers.Adam()\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "E9BCeHlK_r9q"
      },
      "outputs": [],
      "source": [
        "# Fetch the dataset directly\n",
        "dataset = tfds.image_classification.Cifar10()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "fB6j9J1X_r9t"
      },
      "outputs": [],
      "source": [
        "# Download the data, prepare it, and write it to disk\n",
        "dataset.download_and_prepare()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "h7g-dc0z_r9r"
      },
      "outputs": [],
      "source": [
        "# Describe the dataset with DatasetInfo\n",
        "C = dataset.info.features['label'].num_classes\n",
        "Ntrain = dataset.info.splits['train'].num_examples\n",
        "Ntest = dataset.info.splits['test'].num_examples\n",
        "Nbatch = BATCH_SIZE\n",
        "assert C == 10\n",
        "assert Ntrain == 50000\n",
        "assert Ntest == 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "UjnNf6WK_r9u"
      },
      "outputs": [],
      "source": [
        "# Load data from disk as tf.data.Datasets\n",
        "datasets = dataset.as_dataset()\n",
        "train_dataset, validation_dataset = datasets['train'], datasets['test']\n",
        "assert isinstance(train_dataset, tf.data.Dataset)\n",
        "assert isinstance(validation_dataset, tf.data.Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "AzUtVtzO_r9u"
      },
      "outputs": [],
      "source": [
        "def dataset_generator(dataset, batch_size=256, num_classes=10, is_training=False, color_mode=\"grayscale\"):\n",
        "  images = np.zeros((batch_size, 32, 32, 1))\n",
        "  print(\"intote\")\n",
        "  labels = np.zeros((batch_size, num_classes))\n",
        "  while True:\n",
        "    count = 0 \n",
        "    for sample in tfds.as_numpy(dataset):\n",
        "      image = sample[\"image\"]\n",
        "      label = sample[\"label\"]\n",
        "\n",
        "      if color_mode == \"grayscale\":\n",
        "        # rgb to grayscale\n",
        "        image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "      else: # keep only one channel in RGB\n",
        "        channel_index = list('BGR').index(color_mode.upper())\n",
        "        image = image[:,:,channel_index]\n",
        "\n",
        "      images[count%batch_size] = mobilenet_v2.preprocess_input(np.expand_dims(cv.resize(image, (32, 32)), -1))\n",
        "      labels[count%batch_size] = np.expand_dims(to_categorical(label, num_classes=num_classes), 0)\n",
        "      \n",
        "      count += 1\n",
        "      if (count%batch_size == 0):\n",
        "        yield images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "YdtFaE1O_r9x",
        "outputId": "77234e07-5f69-4319-e0b7-2e60f7033376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "intote\n",
            "Epoch 1/50\n",
            "97/97 [==============================] - ETA: 0s - loss: 2.2982 - accuracy: 0.1878intote\n",
            "97/97 [==============================] - 40s 401ms/step - loss: 2.2960 - accuracy: 0.1882 - val_loss: 2.2181 - val_accuracy: 0.3457\n",
            "Epoch 2/50\n",
            "97/97 [==============================] - 39s 406ms/step - loss: 1.8027 - accuracy: 0.3278 - val_loss: 2.0923 - val_accuracy: 0.4011\n",
            "Epoch 3/50\n",
            "97/97 [==============================] - 41s 427ms/step - loss: 1.6439 - accuracy: 0.3788 - val_loss: 1.9543 - val_accuracy: 0.3940\n",
            "Epoch 4/50\n",
            "97/97 [==============================] - 42s 428ms/step - loss: 1.5699 - accuracy: 0.4074 - val_loss: 1.7140 - val_accuracy: 0.5036\n",
            "Epoch 5/50\n",
            "97/97 [==============================] - 43s 440ms/step - loss: 1.5120 - accuracy: 0.4308 - val_loss: 1.5097 - val_accuracy: 0.5405\n",
            "Epoch 6/50\n",
            "97/97 [==============================] - 43s 441ms/step - loss: 1.4716 - accuracy: 0.4480 - val_loss: 1.3298 - val_accuracy: 0.5736\n",
            "Epoch 7/50\n",
            "97/97 [==============================] - 43s 442ms/step - loss: 1.4197 - accuracy: 0.4662 - val_loss: 1.1937 - val_accuracy: 0.6039\n",
            "Epoch 8/50\n",
            "97/97 [==============================] - 43s 441ms/step - loss: 1.3874 - accuracy: 0.4813 - val_loss: 1.1311 - val_accuracy: 0.6147\n",
            "Epoch 9/50\n",
            "97/97 [==============================] - 43s 440ms/step - loss: 1.3645 - accuracy: 0.4907 - val_loss: 1.0881 - val_accuracy: 0.6339\n",
            "Epoch 10/50\n",
            "97/97 [==============================] - 43s 441ms/step - loss: 1.3187 - accuracy: 0.5050 - val_loss: 1.0676 - val_accuracy: 0.6277\n",
            "\n",
            "Epoch 00010: val_loss improved from inf to 1.06763, saving model to LeNet_5\\cp-0010.ckpt\n",
            "Epoch 11/50\n",
            "97/97 [==============================] - 43s 442ms/step - loss: 1.2845 - accuracy: 0.5127 - val_loss: 1.0604 - val_accuracy: 0.6453\n",
            "Epoch 12/50\n",
            "97/97 [==============================] - 43s 441ms/step - loss: 1.2713 - accuracy: 0.5238 - val_loss: 1.0415 - val_accuracy: 0.6417\n",
            "Epoch 13/50\n",
            "97/97 [==============================] - 43s 440ms/step - loss: 1.2326 - accuracy: 0.5406 - val_loss: 1.0239 - val_accuracy: 0.6467\n",
            "Epoch 14/50\n",
            "97/97 [==============================] - 43s 440ms/step - loss: 1.1956 - accuracy: 0.5537 - val_loss: 1.0115 - val_accuracy: 0.6488\n",
            "Epoch 15/50\n",
            "97/97 [==============================] - 43s 442ms/step - loss: 1.1825 - accuracy: 0.5534 - val_loss: 1.0316 - val_accuracy: 0.6409\n",
            "Epoch 16/50\n",
            "97/97 [==============================] - 44s 449ms/step - loss: 1.1742 - accuracy: 0.5553 - val_loss: 1.0365 - val_accuracy: 0.6439\n",
            "Epoch 17/50\n",
            "97/97 [==============================] - 44s 452ms/step - loss: 1.1560 - accuracy: 0.5623 - val_loss: 1.0110 - val_accuracy: 0.6540\n",
            "Epoch 18/50\n",
            "97/97 [==============================] - 43s 438ms/step - loss: 1.1311 - accuracy: 0.5692 - val_loss: 0.9926 - val_accuracy: 0.6614\n",
            "Epoch 19/50\n",
            "97/97 [==============================] - 42s 435ms/step - loss: 1.1122 - accuracy: 0.5741 - val_loss: 1.0031 - val_accuracy: 0.6542\n",
            "Epoch 20/50\n",
            "97/97 [==============================] - 42s 430ms/step - loss: 1.1050 - accuracy: 0.5794 - val_loss: 0.9819 - val_accuracy: 0.6633\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.06763 to 0.98193, saving model to LeNet_5\\cp-0020.ckpt\n",
            "Epoch 21/50\n",
            "97/97 [==============================] - 42s 435ms/step - loss: 1.0687 - accuracy: 0.5928 - val_loss: 1.0031 - val_accuracy: 0.6572\n",
            "Epoch 22/50\n",
            "97/97 [==============================] - 42s 437ms/step - loss: 1.0525 - accuracy: 0.5955 - val_loss: 0.9908 - val_accuracy: 0.6612\n",
            "Epoch 23/50\n",
            "97/97 [==============================] - 42s 438ms/step - loss: 1.0349 - accuracy: 0.6045 - val_loss: 0.9917 - val_accuracy: 0.6642\n",
            "Epoch 24/50\n",
            "97/97 [==============================] - 42s 437ms/step - loss: 1.0326 - accuracy: 0.6037 - val_loss: 1.0025 - val_accuracy: 0.6654\n",
            "Epoch 25/50\n",
            "97/97 [==============================] - 42s 438ms/step - loss: 1.0021 - accuracy: 0.6140 - val_loss: 0.9977 - val_accuracy: 0.6611\n",
            "Epoch 26/50\n",
            "97/97 [==============================] - 42s 433ms/step - loss: 1.0021 - accuracy: 0.6153 - val_loss: 0.9916 - val_accuracy: 0.6637\n",
            "Epoch 27/50\n",
            "97/97 [==============================] - 42s 433ms/step - loss: 0.9825 - accuracy: 0.6219 - val_loss: 0.9703 - val_accuracy: 0.6704\n",
            "Epoch 28/50\n",
            "97/97 [==============================] - 42s 433ms/step - loss: 0.9667 - accuracy: 0.6317 - val_loss: 1.0054 - val_accuracy: 0.6662\n",
            "Epoch 29/50\n",
            "97/97 [==============================] - 42s 435ms/step - loss: 0.9598 - accuracy: 0.6335 - val_loss: 1.0013 - val_accuracy: 0.6637\n",
            "Epoch 30/50\n",
            "97/97 [==============================] - 42s 437ms/step - loss: 0.9480 - accuracy: 0.6374 - val_loss: 1.0037 - val_accuracy: 0.6653\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.98193\n",
            "Epoch 31/50\n",
            "97/97 [==============================] - 43s 439ms/step - loss: 0.9420 - accuracy: 0.6373 - val_loss: 1.0058 - val_accuracy: 0.6642\n",
            "Epoch 32/50\n",
            "97/97 [==============================] - 43s 440ms/step - loss: 0.9278 - accuracy: 0.6445 - val_loss: 1.0087 - val_accuracy: 0.6674\n",
            "Epoch 33/50\n",
            "97/97 [==============================] - 44s 451ms/step - loss: 0.8932 - accuracy: 0.6522 - val_loss: 1.0129 - val_accuracy: 0.6640\n",
            "Epoch 34/50\n",
            "97/97 [==============================] - 43s 443ms/step - loss: 0.8972 - accuracy: 0.6515 - val_loss: 1.0336 - val_accuracy: 0.6679\n",
            "Epoch 35/50\n",
            "97/97 [==============================] - 42s 437ms/step - loss: 0.8872 - accuracy: 0.6554 - val_loss: 1.0737 - val_accuracy: 0.6554\n",
            "Epoch 36/50\n",
            "97/97 [==============================] - 42s 430ms/step - loss: 0.8883 - accuracy: 0.6580 - val_loss: 1.0572 - val_accuracy: 0.6642\n",
            "Epoch 37/50\n",
            "97/97 [==============================] - 42s 430ms/step - loss: 0.8825 - accuracy: 0.6603 - val_loss: 1.0364 - val_accuracy: 0.6733\n",
            "Epoch 38/50\n",
            "97/97 [==============================] - 42s 431ms/step - loss: 0.8742 - accuracy: 0.6610 - val_loss: 1.0554 - val_accuracy: 0.6646\n",
            "Epoch 39/50\n",
            "97/97 [==============================] - 42s 431ms/step - loss: 0.8567 - accuracy: 0.6661 - val_loss: 1.0645 - val_accuracy: 0.6675\n",
            "Epoch 40/50\n",
            "97/97 [==============================] - 42s 429ms/step - loss: 0.8536 - accuracy: 0.6697 - val_loss: 1.0636 - val_accuracy: 0.6709\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.98193\n",
            "Epoch 41/50\n",
            "97/97 [==============================] - 42s 431ms/step - loss: 0.8352 - accuracy: 0.6744 - val_loss: 1.0601 - val_accuracy: 0.6688\n",
            "Epoch 42/50\n",
            "97/97 [==============================] - 42s 430ms/step - loss: 0.8319 - accuracy: 0.6769 - val_loss: 1.1175 - val_accuracy: 0.6641\n",
            "Epoch 43/50\n",
            "97/97 [==============================] - 42s 430ms/step - loss: 0.8160 - accuracy: 0.6807 - val_loss: 1.0811 - val_accuracy: 0.6730\n",
            "Epoch 44/50\n",
            "97/97 [==============================] - 42s 430ms/step - loss: 0.8075 - accuracy: 0.6833 - val_loss: 1.0853 - val_accuracy: 0.6743\n",
            "Epoch 45/50\n",
            "97/97 [==============================] - 42s 430ms/step - loss: 0.8088 - accuracy: 0.6884 - val_loss: 1.1084 - val_accuracy: 0.6716\n",
            "Epoch 46/50\n",
            "97/97 [==============================] - 42s 429ms/step - loss: 0.7968 - accuracy: 0.6884 - val_loss: 1.1176 - val_accuracy: 0.6771\n",
            "Epoch 47/50\n",
            "97/97 [==============================] - 42s 430ms/step - loss: 0.7882 - accuracy: 0.6895 - val_loss: 1.1530 - val_accuracy: 0.6708\n",
            "Epoch 48/50\n",
            "97/97 [==============================] - 42s 430ms/step - loss: 0.8114 - accuracy: 0.6862 - val_loss: 1.1579 - val_accuracy: 0.6657\n",
            "Epoch 49/50\n",
            "97/97 [==============================] - 42s 429ms/step - loss: 0.7703 - accuracy: 0.6997 - val_loss: 1.1759 - val_accuracy: 0.6662\n",
            "Epoch 50/50\n",
            "97/97 [==============================] - 42s 431ms/step - loss: 0.7789 - accuracy: 0.6951 - val_loss: 1.1374 - val_accuracy: 0.6665\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.98193\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2011d862dc0>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = np.zeros((Ntest))\r\n",
        "pred_labels = np.zeros((Ntest, C))\r\n",
        "pred_labels_new = np.zeros((Ntest, C))\r\n",
        "\r\n",
        "# Train on Cifar10\r\n",
        "checkpoint_path = \"LeNet_5/cp-{epoch:04d}.ckpt\"\r\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\r\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\r\n",
        "\r\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(\r\n",
        "    checkpoint_path,\r\n",
        "    verbose=1,\r\n",
        "    monitor=\"val_loss\",\r\n",
        "    mode='auto',\r\n",
        "    save_weights_only=True,\r\n",
        "    save_best_only=True,\r\n",
        "    period=10\r\n",
        ")\r\n",
        "    \r\n",
        "csv_logger = keras.callbacks.CSVLogger('LeNet_5.csv')\r\n",
        "\r\n",
        "\r\n",
        "model.fit(\r\n",
        "    dataset_generator(train_dataset, batch_size=Nbatch, is_training=True, color_mode=COLOR_MODE),\r\n",
        "    steps_per_epoch= Ntrain // Nbatch,\r\n",
        "    epochs = EPOCHS,\r\n",
        "    validation_data = dataset_generator(validation_dataset, batch_size=Nbatch, color_mode=COLOR_MODE),\r\n",
        "    validation_steps = Ntest // Nbatch,\r\n",
        "    callbacks = [cp_callback, csv_logger]\r\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "2OTRMvnu_r9w"
      },
      "outputs": [
        {
          "ename": "NotFoundError",
          "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for LeNet_5/cp-{epoch:04d}.ckpt",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mD:\\Python38\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[1;34m(filepattern)\u001b[0m\n\u001b[0;32m     94\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m   \u001b[1;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for LeNet_5/cp-{epoch:04d}.ckpt",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-56-806d829868f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m score = model.evaluate_generator(\n\u001b[0;32m      3\u001b[0m     \u001b[0mdataset_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcolor_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCOLOR_MODE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mNtest\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mNbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2268\u001b[0m           'True when by_name is True.')\n\u001b[0;32m   2269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2270\u001b[1;33m     \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_detect_save_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tf'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2272\u001b[0m       \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_detect_save_format\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m   2891\u001b[0m   \u001b[1;31m# directory. It's possible for filepath to be both a prefix and directory.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2892\u001b[0m   \u001b[1;31m# Prioritize checkpoint over SavedModel.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2893\u001b[1;33m   \u001b[1;32mif\u001b[0m \u001b[0m_is_readable_tf_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2894\u001b[0m     \u001b[0msave_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'tf'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2895\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python38\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_is_readable_tf_checkpoint\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m   2912\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_is_readable_tf_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2913\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2914\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2915\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2916\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLossError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python38\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[1;34m(filepattern)\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[1;31m# issue with throwing python exceptions from C++.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0merror_translator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mD:\\Python38\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m     33\u001b[0m       \u001b[1;34m'Failed to find any '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m       'matching files for') in error_message:\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m   elif 'Sliced checkpoints are not supported' in error_message or (\n\u001b[0;32m     37\u001b[0m       \u001b[1;34m'Data type '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for LeNet_5/cp-{epoch:04d}.ckpt"
          ]
        }
      ],
      "source": [
        "model.load_weights(checkpoint_path)\r\n",
        "score = model.evaluate_generator(\r\n",
        "    dataset_generator(validation_dataset,batch_size=Nbatch),\r\n",
        "    color_mode=COLOR_MODE,\r\n",
        "    steps= Ntest // Nbatch,\r\n",
        "    verbose=1,)\r\n",
        "\r\n",
        "print(\"Evaluation Result of new Model on cifar100: \" + str(score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-MLTzQX_r91"
      },
      "outputs": [],
      "source": [
        "model.save(\"LeNet_{}_{:04d}.h5\".format(COLOR_MODE, int(score[-1]*10000)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "grayscale_vs_one_of_rgb_channel.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "95ab7303ed2746327945aa376054eddca8c4eca362915ff95db932dbe7e7ee41"
    },
    "kernelspec": {
      "display_name": "Python 3.8.7 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}